{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running main\n",
      "*****Running main_io with default out_folder_name*****\n",
      "Solver ran in 7.336714299992309 seconds\n",
      "Calibrating with alpha_lab_targ = 0.33496439, w0_mean_targ = 2.1986477, w0_sd_targ = 0.29952401, \n",
      "                                        w1_targ = 0.2915204, w2_targ = 0.27134400000000003, wH_targ = 0.051474661,\n",
      "                                        dpi_BB_targ = 0.50886095, dpi_GG_targ = 0.34358001\n",
      "***** Calibration iteration 0 *****\n",
      "Calibrating delta_pi_BB and delta_pi_GG\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "***** Calibration iteration 1 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "***** Calibration iteration 2 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 3 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 4 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 5 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 6 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 7 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 8 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "Calibrating wH\n",
      "***** Calibration iteration 9 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "***** Calibration iteration 10 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 11 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 12 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 13 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "Calibrating wH\n",
      "***** Calibration iteration 14 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "Calibrating wH\n",
      "Calibrating alpha\n",
      "Calibration converged after 15 iterations\n",
      "delta_pi_BB = -0.02968749999999999, delta_pi_BB mom = 0.5091329667909736, delta_pi_BB mom targ = 0.50886095\n",
      "delta_pi_GG = 0.24855078125, delta_pi_GG mom = 0.3426309387303898, delta_pi_GG mom targ = 0.34358001\n",
      "w0_weights = [0.07944945 0.21727989 0.26085056 0.20025263 0.12080038 0.06365817\n",
      " 0.03106158 0.01451676 0.00663286 0.00549772], w0_mean = 2.198214706264663, w0_mean_targ = 2.1986477\n",
      "w0_sd = 0.2987335702605303, w0_sd_targ = 0.29952401\n",
      "w1 = 0.022430419921875, w1 moment = 0.2912761550653373, w1 mom targ = 0.2915204\n",
      "w2 = -0.0004444122314453125, w2 moment = 0.2705918141198116, w2 mom targ = 0.27134400000000003\n",
      "wH = 0.04150390625, wH moment = 0.0507931218653801, wH mom targ = 0.051474661\n",
      "alpha = 0.3789124609375, alpha moment = 0.3356043799540735, alpha mom targ = 0.33496439\n",
      "Calibration ran in 268.9131422000064 seconds\n"
     ]
    }
   ],
   "source": [
    "import main\n",
    "import plot_inequality as plot_ineq\n",
    "import time\n",
    "import importlib\n",
    "import io_manager\n",
    "importlib.reload(plot_ineq)\n",
    "#run stuff here\n",
    "start_time = time.perf_counter()\n",
    "print(\"Running main\")\n",
    "\n",
    "of_name = None\n",
    "main_path = \"C:/Users/Ben/My Drive/PhD/PhD Year 3/3rd Year Paper/Model/My Code/MH_Model/my_code/model_uncert/\"\n",
    "trans_path = main_path + \"input/50p_age_moms/MH_trans_uncond_age.csv\"\n",
    "main_path = \"C:/Users/Ben/My Drive/PhD/PhD Year 3/3rd Year Paper/Model/My Code/MH_Model/my_code/model_uncert/\"\n",
    "\n",
    "output_flag = False\n",
    "myPars, myShocks, sols, sims = main.main_io(main_path, out_folder_name = of_name, H_trans_uncond_path = trans_path, output_flag = output_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted percentile (manual): 0.49676990335736615\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def weighted_percentile(values: np.ndarray, weights: np.ndarray, percentile: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate weighted percentile manually.\n",
    "    \n",
    "    Parameters:\n",
    "    values (np.ndarray): Array of data values.\n",
    "    weights (np.ndarray): Array of corresponding weights.\n",
    "    percentile (float): Percentile to compute (0-100).\n",
    "    \n",
    "    Returns:\n",
    "    float: Weighted percentile value.\n",
    "    \"\"\"\n",
    "    # Step 1: Sort the data and weights by the data values\n",
    "    sorted_indices = np.argsort(values)\n",
    "    sorted_values = values[sorted_indices]\n",
    "    sorted_weights = weights[sorted_indices]\n",
    "\n",
    "    # Step 2: Compute the cumulative sum of the weights\n",
    "    cumulative_weights = np.cumsum(sorted_weights)\n",
    "    total_weight = cumulative_weights[-1]\n",
    "\n",
    "    # Step 3: Find the index where the cumulative weight exceeds the desired percentile\n",
    "    percentile_threshold = percentile / 100.0 * total_weight\n",
    "    percentile_idx = np.searchsorted(cumulative_weights, percentile_threshold)\n",
    "\n",
    "    # Step 4: Return the value at the computed percentile index\n",
    "    return sorted_values[percentile_idx]\n",
    "\n",
    "def wperc_combined(\n",
    "    data: np.ndarray, \n",
    "    weights: np.ndarray, \n",
    "    percentile: float\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate weighted percentile manually by combining specific weights for the first two \n",
    "    dimensions with even weights along the third dimension.\n",
    "    \n",
    "    Parameters:\n",
    "    data (np.ndarray): 3D array of shape (dim1, dim2, dim3).\n",
    "    weights (np.ndarray): 2D weight array for the first two dimensions (dim1, dim2).\n",
    "    percentile (float): Percentile to calculate (0-100).\n",
    "    \n",
    "    Returns:\n",
    "    float: Weighted percentile.\n",
    "    \"\"\"\n",
    "    dim1, dim2, dim3 = data.shape\n",
    "    \n",
    "    # Step 1: Flatten the first two dimensions\n",
    "    flattened_data = data.reshape(dim1 * dim2, dim3)\n",
    "    \n",
    "    # Step 2: Apply even weights along the third dimension\n",
    "    even_weights = np.ones(dim3) / dim3\n",
    "    \n",
    "    # Step 3: Combine specific weights and even weights\n",
    "    combined_weights = np.repeat(weights.flatten(), dim3) * np.tile(even_weights, dim1 * dim2)\n",
    "    \n",
    "    # Step 4: Flatten the data to 1D\n",
    "    flattened_data_1d = flattened_data.flatten()\n",
    "    \n",
    "    # Step 5: Calculate weighted percentile manually\n",
    "    percentile_value = weighted_percentile(flattened_data_1d, combined_weights, percentile)\n",
    "    \n",
    "    return percentile_value\n",
    "\n",
    "# Example usage:\n",
    "data = np.random.rand(4, 3, 5)  # 3D data array\n",
    "weights = np.random.rand(4, 3)  # 2D weights\n",
    "percentile = 50  # 50th percentile (median)\n",
    "\n",
    "result = wperc_combined(data, weights, percentile)\n",
    "print(f\"Weighted percentile (manual): {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2, 1000, 31)\n",
      "(10, 2, 1000)\n",
      "(10,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "import model_uncert as model\n",
    "import numpy as np\n",
    "from pars_shocks import Pars, Shocks\n",
    "def collapse_lifetime_earn(myPars: Pars, earn_sims: np.ndarray):\n",
    "    age_25_ind = np.where(myPars.age_grid == 25)[0][0]\n",
    "    age_55_ind = np.where(myPars.age_grid == 55)[0][0]\n",
    "    earn_sims_trim = earn_sims[:, :, :, age_25_ind:age_55_ind+1]\n",
    "    print(earn_sims_trim.shape)\n",
    "    lifetime_earn_sum = np.sum(earn_sims_trim, axis = -1)\n",
    "    print(lifetime_earn_sum.shape)\n",
    "    lifetime_earn = lifetime_earn_sum / 31 \n",
    "    return lifetime_earn\n",
    "\n",
    "def lifetime_earn_stats(lifetime_earn: np.ndarray):\n",
    "    print(f\"raw mean lifetime earn: {np.mean(lifetime_earn)}\")\n",
    "    pass\n",
    "    # return mean, median, p10, p25, p75, p90\n",
    "\n",
    "def lifetime_earn_perc(myPars: Pars, lifetime_earn: np.ndarray, percentile: float):\n",
    "    weights0 = myPars.lab_fe_weights\n",
    "    weights1 = myPars.H_type_perm_weights\n",
    "    print(weights0.shape)\n",
    "    print(weights1.shape)\n",
    "    weights = np.array\n",
    "    pass\n",
    "\n",
    "earn_sims = sims['lab_earnings']\n",
    "lifetime_earn = collapse_lifetime_earn(myPars, earn_sims)\n",
    "lifetime_earn_perc(myPars, lifetime_earn, 90)\n",
    "\n",
    "# lifetime_earn_stats(lifetime_earn)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
