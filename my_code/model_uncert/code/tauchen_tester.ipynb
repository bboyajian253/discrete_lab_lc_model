{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default health transition matrix\n"
     ]
    }
   ],
   "source": [
    "import my_toolbox as tb\n",
    "import numpy as np\n",
    "import calibration as calib\n",
    "import main\n",
    "import importlib\n",
    "\n",
    "importlib.reload(main)\n",
    "\n",
    "main_path = \"C:/Users/Ben/My Drive/PhD/PhD Year 3/3rd Year Paper/Model/My Code/MH_Model/my_code/model_uncert/\"\n",
    "my_lab_fe_grid = np.log(np.array([5.0, 10.0, 15.0, 20.0]))\n",
    "myPars = main.pars_factory(main_path, my_lab_fe_grid = my_lab_fe_grid) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from typing import Tuple\n",
    "from math import erf, sqrt, exp, pi\n",
    "from numba import njit\n",
    "\n",
    "def Taucheniid(sigma:float, num_grid_points: int, Nsd: int=3, mean:float=0.0, state_grid: np.ndarray=np.zeros(1))->Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    This function uses the method of Tauchen (1986) to approximate a continuous iid Normal process.\n",
    "\n",
    "    Normal process: ε~N(0, σ**2).\n",
    "\n",
    "    INPUTS:  -σ: SD of innovation in AR(1) process\n",
    "             -S: number of gridpoints\n",
    "             -Nsd: number of SD from mean for grid to span\n",
    "\n",
    "    OUTPUTS: -state_grid, grid of state variable s\n",
    "             -probs, grid of probabilities for each state\n",
    "    \"\"\"\n",
    "    # compute grid over state s and the half-distance between gridpoints, δ\n",
    "    if len(state_grid) == 1:\n",
    "        state_grid = np.linspace(mean - Nsd * sigma, mean + Nsd * sigma, num_grid_points)\n",
    "    δ = (state_grid[-1] - state_grid[0]) / (num_grid_points - 1) / 2\n",
    "\n",
    "    # compute cumulative probabilities of state_grid\n",
    "    probscum = np.ones(num_grid_points)\n",
    "    for s in range(num_grid_points - 1):\n",
    "        probscum[s] = norm.cdf(state_grid[s] + δ, loc=mean, scale=sigma)\n",
    "\n",
    "    # compute probabilities of state_grid\n",
    "    probs = probscum\n",
    "    probs[1:] = probscum[1:] - probscum[:-1]\n",
    "\n",
    "    return probs, state_grid\n",
    "\n",
    "\n",
    "@njit\n",
    "def normal_cdf_numba(x, mean=0.0, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Numba-compatible approximation for the CDF of the normal distribution.\n",
    "    Uses the error function (erf) to compute the CDF.\n",
    "    \"\"\"\n",
    "    return 0.5 * (1 + erf((x - mean) / (sigma * sqrt(2))))\n",
    "\n",
    "@njit\n",
    "def Taucheniid_numba(sigma: float, num_grid_points: int, Nsd: int = 3, mean: float = 0.0, state_grid: np.ndarray = np.zeros(1)) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Numba-compatible version of the Taucheniid function to approximate a continuous iid Normal process.\n",
    "\n",
    "    Normal process: ε ~ N(0, σ**2).\n",
    "\n",
    "    INPUTS:  - σ: SD of innovation in AR(1) process\n",
    "             - num_grid_points: number of grid points\n",
    "             - Nsd: number of standard deviations from the mean for grid to span\n",
    "\n",
    "    OUTPUTS: - state_grid: grid of state variable s\n",
    "             - probs: grid of probabilities for each state\n",
    "    \"\"\"\n",
    "    # Compute grid over state s and the half-distance between grid points (δ)\n",
    "    if len(state_grid) == 1:\n",
    "        state_grid = np.linspace(mean - Nsd * sigma, mean + Nsd * sigma, num_grid_points)\n",
    "    δ = (state_grid[-1] - state_grid[0]) / (num_grid_points - 1) / 2\n",
    "\n",
    "    # Compute cumulative probabilities of state_grid using normal_cdf\n",
    "    probscum = np.ones(num_grid_points)\n",
    "    for s in range(num_grid_points - 1):\n",
    "        probscum[s] = normal_cdf_numba(state_grid[s] + δ, mean=mean, sigma=sigma)\n",
    "\n",
    "    # Compute probabilities of state_grid\n",
    "    probs = probscum.copy()  # Copy to avoid modifying in place\n",
    "    probs[1:] = probscum[1:] - probscum[:-1]\n",
    "\n",
    "    return probs, state_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tauch weights: [0.01350746 0.5835354  0.39951823 0.00343891]\n",
      "Tauchen grid: [ 5. 10. 15. 20.]\n",
      "Tauch mean: 11.964442972449088\n",
      "Tauch variance: 6.81049716158292\n",
      "Tauch weights numba: [0.01350746 0.5835354  0.39951823 0.00343891]\n",
      "Tauchen grid numba: [ 5. 10. 15. 20.]\n",
      "Tauch mean numba: 11.964442972449088\n",
      "Tauch variance numba: 6.81049716158292\n",
      "Given mu: 12.0, model mu moment: 13.730126231302608, target mu moment: 12.5\n",
      "Given sigma: 2.035, model sigma moment: 3.462460905275781, target sigma moment: 3.5\n",
      "Given mu: 12.0, model mu moment: 13.730126231302608, target mu moment: 12.5\n",
      "Given sigma: 2.035, model sigma moment: 3.462460905275781, target sigma moment: 3.5\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(calib)\n",
    "mu = 12.0\n",
    "sigma = 2.035\n",
    "\n",
    "mu_mom_targ = 12.5\n",
    "sigma_mom_targ = 3.5\n",
    "# my_grid = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "# my_grid = np.log(np.array([5.0, 10.0, 15.0, 20.0]))\n",
    "my_grid = np.array([5.0, 10.0, 15.0, 20.0])\n",
    "# my_grid = np.log(my_grid)\n",
    "\n",
    "tauch_weights, tauch_grid = Taucheniid(sigma, len(my_grid), Nsd = 3, mean = mu, state_grid = my_grid)\n",
    "tauch_weights_numba, tauch_grid_numba = Taucheniid_numba(sigma, len(my_grid), Nsd = 3, mean = mu, state_grid = my_grid)\n",
    "\n",
    "# print tauch results\n",
    "myPars.lab_fe_weights = tauch_weights \n",
    "mean = np.sum(tauch_weights*tauch_grid)\n",
    "variance = np.sum(tauch_weights*(tauch_grid - mean)**2)\n",
    "print(f\"Tauch weights: {tauch_weights}\")\n",
    "print(f\"Tauchen grid: {tauch_grid}\")\n",
    "print(f\"Tauch mean: {mean}\")\n",
    "print(f\"Tauch variance: {variance}\")\n",
    "\n",
    "\n",
    "# print tauch numba results\n",
    "myPars.lab_fe_weights = tauch_weights_numba\n",
    "mean = np.sum(tauch_weights_numba*tauch_grid_numba)\n",
    "variance = np.sum(tauch_weights_numba*(tauch_grid_numba - mean)**2)\n",
    "print(f\"Tauch weights numba: {tauch_weights_numba}\")\n",
    "print(f\"Tauchen grid numba: {tauch_grid_numba}\")\n",
    "print(f\"Tauch mean numba: {mean}\")\n",
    "print(f\"Tauch variance numba: {variance}\")\n",
    "\n",
    "# compute model moments to match\n",
    "my_w0_mu_mom = calib.w0_mu_moment(myPars)\n",
    "print(f\"Given mu: {mu}, model mu moment: {my_w0_mu_mom}, target mu moment: {mu_mom_targ}\")\n",
    "my_w0_sigma_mom = calib.w0_sigma_moment(myPars)\n",
    "print(f\"Given sigma: {sigma}, model sigma moment: {my_w0_sigma_mom}, target sigma moment: {sigma_mom_targ}\")\n",
    "\n",
    "# compute model moments to match\n",
    "myPars.lab_fe_weights = tauch_weights_numba\n",
    "my_w0_mu_mom = calib.w0_mu_moment(myPars)\n",
    "print(f\"Given mu: {mu}, model mu moment: {my_w0_mu_mom}, target mu moment: {mu_mom_targ}\")\n",
    "my_w0_sigma_mom = calib.w0_sigma_moment(myPars)\n",
    "print(f\"Given sigma: {sigma}, model sigma moment: {my_w0_sigma_mom}, target sigma moment: {sigma_mom_targ}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
