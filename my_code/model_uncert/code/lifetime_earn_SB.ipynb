{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running main\n",
      "*****Running main_io with default out_folder_name*****\n",
      "Solver ran in 7.12398909998592 seconds\n",
      "Calibrating with alpha_lab_targ = 0.33497447, w0_mean_targ = 2.1988928, w0_sd_targ = 0.29847395, \n",
      "                                        w1_targ = 0.2928040000000003, w2_targ = 0.2746706000000003, wH_targ = 0.051316846, phi_H_targ = 0.053118114,\n",
      "                                        dpi_BB_targ = 0.50886095, dpi_GG_targ = 0.34358001\n",
      "***** Calibration iteration 0 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "***** Calibration iteration 1 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "***** Calibration iteration 2 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 3 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 4 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 5 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 6 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 7 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 8 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 9 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "Calibrating wH\n",
      "***** Calibration iteration 10 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "***** Calibration iteration 11 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 12 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 13 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "Calibrating wH\n",
      "***** Calibration iteration 14 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "Calibrating wH\n",
      "Calibrating alpha\n",
      "Calibration converged after 15 iterations\n",
      "********** delta_pi_BB and delta_pi_GG calibration was skipped **********\n",
      "********** phi_H calibration was skipped **********\n",
      "delta_pi_BB = 0.0, delta_pi_BB mom = 0.4700454418326594, delta_pi_BB mom targ = 0.50886095\n",
      "delta_pi_GG = 0.0, delta_pi_GG mom = 0.3330674573347202, delta_pi_GG mom targ = 0.34358001\n",
      "w0_weights = [0.08364875 0.22278452 0.26211563 0.19789699 0.11771067 0.06128179\n",
      " 0.0295854  0.0136965  0.00620493 0.00507483], w0_mean = 2.199488850043287, w0_mean_targ = 2.1988928\n",
      "w0_sd = 0.2991246776023337, w0_sd_targ = 0.29847395\n",
      "w1 = 0.0231170654296875, w1 moment = 0.29318318830635537, w1 mom targ = 0.2928040000000003\n",
      "w2 = -0.0004596710205078125, w2 moment = 0.27552217133529266, w2 mom targ = 0.2746706000000003\n",
      "wH = 0.059814453125, wH moment = 0.051443689494116374, wH mom targ = 0.051316846\n",
      "phi_H = 0.0, phi_H moment = 0.015364875479543016, phi_H mom targ = 0.053118114\n",
      "alpha = 0.3789124609375, alpha moment = 0.33481536475148743, alpha mom targ = 0.33497447\n",
      "Calibration ran in 261.7503313999914 seconds\n"
     ]
    }
   ],
   "source": [
    "import main\n",
    "import plot_inequality as plot_ineq\n",
    "import time\n",
    "import importlib\n",
    "import io_manager\n",
    "import numpy as np\n",
    "importlib.reload(plot_ineq)\n",
    "#run stuff here\n",
    "start_time = time.perf_counter()\n",
    "print(\"Running main\")\n",
    "\n",
    "of_name = None\n",
    "main_path = \"C:/Users/Ben/My Drive/PhD/PhD Year 3/3rd Year Paper/Model/My Code/MH_Model/my_code/model_uncert/\"\n",
    "input_path = main_path + \"input/50p_age_moms/\"\n",
    "trans_path_uncond = input_path + \"MH_trans_uncond_age.csv\"\n",
    "\n",
    "trans_path_50p = input_path + \"MH_trans_by_MH_clust_age.csv\"\n",
    "type_path_50p = input_path + \"MH_clust_50p_age_pop_shares.csv\"\n",
    "\n",
    "do_dpi_calib = False\n",
    "output_flag = False\n",
    "myPars, myShocks, sols, sims = main.main_io(main_path, out_folder_name = of_name, \n",
    "                                            H_trans_uncond_path = trans_path_uncond, \n",
    "                                            H_trans_path = trans_path_50p, H_type_pop_share_path = type_path_50p,\n",
    "                                            output_flag = output_flag, do_dpi_calib = do_dpi_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.mean(H_hist) 1.0\n",
      "*****Running main_io with default out_folder_name*****\n",
      "Solver ran in 0.5157232000201475 seconds\n",
      "Calibrating with alpha_lab_targ = 0.33497447, w0_mean_targ = 2.1988928, w0_sd_targ = 0.29847395, \n",
      "                                        w1_targ = 0.2928040000000003, w2_targ = 0.2746706000000003, wH_targ = 0.051316846, phi_H_targ = 0.053118114,\n",
      "                                        dpi_BB_targ = 0.50886095, dpi_GG_targ = 0.34358001\n",
      "***** Calibration iteration 0 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "***** Calibration iteration 1 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "***** Calibration iteration 2 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 3 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 4 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 5 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 6 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 7 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 8 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 9 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "Calibrating alpha\n",
      "Calibration converged after 10 iterations\n",
      "********** delta_pi_BB and delta_pi_GG calibration was skipped **********\n",
      "********** wH calibration was skipped **********\n",
      "********** phi_H calibration was skipped **********\n",
      "delta_pi_BB = 0.0, delta_pi_BB mom = 0.4700454418326594, delta_pi_BB mom targ = 0.50886095\n",
      "delta_pi_GG = 0.0, delta_pi_GG mom = 0.3330674573347202, delta_pi_GG mom targ = 0.34358001\n",
      "w0_weights = [0.12679962 0.29886625 0.28411331 0.16668549 0.07595742 0.03022288\n",
      " 0.01118742 0.00399455 0.00140565 0.00076739], w0_mean = 2.199476661214101, w0_mean_targ = 2.1988928\n",
      "w0_sd = 0.2985280117977774, w0_sd_targ = 0.29847395\n",
      "w1 = 0.0231170654296875, w1 moment = 0.2933362721776991, w1 mom targ = 0.2928040000000003\n",
      "w2 = -0.0004730224609375, w2 moment = 0.27441383907794137, w2 mom targ = 0.2746706000000003\n",
      "wH = 0.25, wH moment = 0.23910194496291703, wH mom targ = 0.051316846\n",
      "phi_H = 0.0, phi_H moment = 0.07703801662695836, phi_H mom targ = 0.053118114\n",
      "alpha = 0.38477177734374995, alpha moment = 0.335479112658742, alpha mom targ = 0.33497447\n",
      "Calibration ran in 152.427509000001 seconds\n",
      "*****Running main_io with default out_folder_name*****\n",
      "Solver ran in 0.5121561999840196 seconds\n",
      "Calibrating with alpha_lab_targ = 0.33497447, w0_mean_targ = 2.1988928, w0_sd_targ = 0.29847395, \n",
      "                                        w1_targ = 0.2928040000000003, w2_targ = 0.2746706000000003, wH_targ = 0.051316846, phi_H_targ = 0.053118114,\n",
      "                                        dpi_BB_targ = 0.50886095, dpi_GG_targ = 0.34358001\n",
      "***** Calibration iteration 0 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "***** Calibration iteration 1 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 2 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 3 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 4 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 5 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 6 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "***** Calibration iteration 7 *****\n",
      "Calibrating w0_mu\n",
      "Calibrating w0_sigma\n",
      "Calibrating w1\n",
      "Calibrating w2\n",
      "Calibrating alpha\n",
      "Calibration converged after 8 iterations\n",
      "********** delta_pi_BB and delta_pi_GG calibration was skipped **********\n",
      "********** wH calibration was skipped **********\n",
      "********** phi_H calibration was skipped **********\n",
      "delta_pi_BB = 0.0, delta_pi_BB mom = 0.4700454418326594, delta_pi_BB mom targ = 0.50886095\n",
      "delta_pi_GG = 0.0, delta_pi_GG mom = 0.3330674573347202, delta_pi_GG mom targ = 0.34358001\n",
      "w0_weights = [0.06854045 0.2017959  0.25632138 0.20616813 0.12936483 0.07052623\n",
      " 0.03545355 0.01701457 0.00796197 0.00685299], w0_mean = 2.199395927484931, w0_mean_targ = 2.1988928\n",
      "w0_sd = 0.298957533172566, w0_sd_targ = 0.29847395\n",
      "w1 = 0.0231170654296875, w1 moment = 0.2936124713553787, w1 mom targ = 0.2928040000000003\n",
      "w2 = -0.00045490264892578125, w2 moment = 0.2750158227431707, w2 mom targ = 0.2746706000000003\n",
      "wH = 0.0, wH moment = -0.007422423909750009, wH mom targ = 0.051316846\n",
      "phi_H = 0.0, phi_H moment = -0.0037323003443515135, phi_H mom targ = 0.053118114\n",
      "alpha = 0.3789124609375, alpha moment = 0.33506423754982434, alpha mom targ = 0.33497447\n",
      "Calibration ran in 126.7450101999857 seconds\n"
     ]
    }
   ],
   "source": [
    "from pars_shocks import Pars, Shocks\n",
    "import pars_shocks\n",
    "importlib.reload(main)\n",
    "\n",
    "# calib phi_H: time cost counterfactual\n",
    "# myPars_tc, myShocks_tc, sols_tc, sims_tc = main.main_io(main_path, out_folder_name = of_name,\n",
    "#                                                         H_trans_uncond_path = trans_path_uncond, \n",
    "#                                                         H_trans_path = trans_path_50p, H_type_pop_share_path = type_path_50p,\n",
    "#                                                         output_flag = False, do_dpi_calib = False, do_phi_H_calib=True) \n",
    "# H = good counterfactual\n",
    "myPars_H_good: Pars = main.pars_factory(main_path, \n",
    "                                        H_trans_uncond_path = trans_path_uncond, \n",
    "                                        H_trans_path = trans_path_50p, H_type_pop_share_path = type_path_50p)\n",
    "myShocks_H_good: Shocks = Shocks(myPars_H_good)\n",
    "\n",
    "H_hist = np.ones(myPars.state_space_shape_sims, dtype=np.int64)\n",
    "myShocks_H_good.H_hist = H_hist\n",
    "print(\"np.mean(H_hist)\", np.mean(H_hist))\n",
    "\n",
    "myPars_H_good, myShocks_H_good, sols_H_good, sims_H_good = main.main_io(main_path, out_folder_name = of_name, \n",
    "                                                                    H_trans_uncond_path = trans_path_uncond, \n",
    "                                                                    H_trans_path = trans_path_50p, H_type_pop_share_path = type_path_50p,\n",
    "                                                                    myPars = myPars_H_good, myShocks=myShocks_H_good, \n",
    "                                                                    output_flag = False, do_wH_calib = False, do_dpi_calib = False)\n",
    "\n",
    "# wH = 0 counterfactual\n",
    "myPars_no_wH: Pars = main.pars_factory(main_path,\n",
    "                                        H_trans_uncond_path = trans_path_uncond, \n",
    "                                        H_trans_path = trans_path_50p, H_type_pop_share_path = type_path_50p)\n",
    "myPars_no_wH.wH_coeff = 0.0\n",
    "myPars_no_wH, myShocks_no_wH, sols_no_wH, sims_no_wH = main.main_io(main_path, out_folder_name = of_name,\n",
    "                                                                    H_trans_uncond_path = trans_path_uncond, \n",
    "                                                                    H_trans_path = trans_path_50p, H_type_pop_share_path = type_path_50p,\n",
    "                                                                    myPars = myPars_no_wH, myShocks=myShocks, \n",
    "                                                                    output_flag = False, do_wH_calib = False, do_dpi_calib = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_uncert as model\n",
    "from typing import Tuple\n",
    "age_25_ind = np.where(myPars.age_grid == 25)[0][0] \n",
    "age_55_ind = np.where(myPars.age_grid == 55)[0][0]\n",
    "\n",
    "lab_earn_trim: np.array = sims[\"lab_earnings\"][:, :, :, age_25_ind:age_55_ind+1]*12\n",
    "lab_earn_trim_no_wH: np.array = sims_no_wH[\"lab_earnings\"][:, :, :, age_25_ind:age_55_ind+1]*12\n",
    "lab_earn_trim_H_good: np.array = sims_H_good[\"lab_earnings\"][:, :, :, age_25_ind:age_55_ind+1]*12\n",
    "# lab_earn_trim_tc: np.array = sims_tc[\"lab_earnings\"][:, :, :, age_25_ind:age_55_ind+1]*12\n",
    "\n",
    "log_lab_earn = np.log(lab_earn_trim)\n",
    "log_lab_earn_no_wH = np.log(lab_earn_trim_no_wH)\n",
    "log_lab_earn_H_good = np.log(lab_earn_trim_H_good)\n",
    "# log_lab_earn_tc = np.log(lab_earn_trim_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_wstats(earnings: np.array, weights_lab_fe: np.array, weight_H_type: np.array) -> dict:\n",
    "\n",
    "    weights = np.outer(weights_lab_fe, weight_H_type)\n",
    "    sim_num = earnings.shape[2]\n",
    "    age_num = earnings.shape[3]\n",
    "    weights_exp = np.repeat(weights[:, :, np.newaxis], sim_num, axis=2)\n",
    "    weights_exp = np.repeat(weights_exp[:, :, :, np.newaxis], age_num, axis=3)\n",
    "\n",
    "    flat_earns = earnings.flatten()\n",
    "    flat_weights = weights_exp.flatten()\n",
    "\n",
    "    mean_earn = np.average(flat_earns, weights=flat_weights)\n",
    "\n",
    "    #calculate the weighted median\n",
    "    sorted_inds = np.argsort(flat_earns)\n",
    "    sorted_earns = flat_earns[sorted_inds]\n",
    "    sorted_weights = flat_weights[sorted_inds]\n",
    "    cum_weights = np.cumsum(sorted_weights)\n",
    "    cutoff = 0.5 * cum_weights[-1]\n",
    "    median_earn = sorted_earns[np.searchsorted(cum_weights, cutoff)]\n",
    "\n",
    "    #calc weighted variance\n",
    "    var_earn = np.average((flat_earns - mean_earn)**2, weights=flat_weights)\n",
    "    #calc weighted std dev\n",
    "    std_earn = np.sqrt(var_earn)\n",
    "\n",
    "    #calc weighted min and max\n",
    "    min_earn = np.min(flat_earns)\n",
    "    max_earn = np.max(flat_earns)\n",
    "\n",
    "    # Calculate weighted percentiles\n",
    "    pct_10 = np.percentile(sorted_earns, 10)\n",
    "    pct_25 = np.percentile(sorted_earns, 25)\n",
    "    pct_75 = np.percentile(sorted_earns, 75)\n",
    "    pct_90 = np.percentile(sorted_earns, 90)\n",
    "\n",
    "    # Step 5: Return the results in a dictionary\n",
    "    ret_dict = {\n",
    "        \"mean\": mean_earn,\n",
    "        \"median\": median_earn,\n",
    "        \"var\": var_earn,\n",
    "        \"std_dev\": std_earn,\n",
    "        \"min\": min_earn,\n",
    "        \"max\": max_earn,\n",
    "        \"P10\": pct_10,\n",
    "        \"P25\": pct_25,\n",
    "        \"P75\": pct_75,\n",
    "        \"P90\": pct_90\n",
    "    }\n",
    "\n",
    "    return ret_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_weighted_lt_stats(earnings: np.array, weights_lab_fe: np.array, weights_H_type: np.array) -> dict:\n",
    "    # Step 1: Calculate lifetime earnings (annualized mean earnings from ages 25-55)\n",
    "    # Average across the last axis (age), assuming the earnings matrix is already restricted to ages 25-55.\n",
    "    lifetime_earnings = earnings.mean(axis=-1)  # Shape: (lab_fe, H_type, simulation_number)\n",
    "    \n",
    "    # Step 2: Expand the weights to match the dimensions of lifetime_earnings\n",
    "    # Create a grid of weights by multiplying the lab_fe and H_type weights\n",
    "    weights = np.outer(weights_lab_fe, weights_H_type)  # Shape: (lab_fe, H_type)\n",
    "    \n",
    "    # Reshape the weights to broadcast over the (simulation_number) dimension\n",
    "    sim_num = lifetime_earnings.shape[2]\n",
    "    weights_expanded = np.repeat(weights[:, :, np.newaxis], sim_num, axis=2)  # Shape: (lab_fe, H_type, simulation_number)\n",
    "\n",
    "    # Step 3: Flatten the earnings and weights for weighted calculation\n",
    "    flattened_earnings = lifetime_earnings.flatten()  # Shape: (lab_fe * H_type * simulation_number,)\n",
    "    flattened_weights = weights_expanded.flatten()    # Shape: (lab_fe * H_type * simulation_number,)\n",
    "\n",
    "    # Step 4: Compute weighted statistics\n",
    "\n",
    "    # Calculate weighted mean\n",
    "    mean_earn = np.average(flattened_earnings, weights=flattened_weights)\n",
    "\n",
    "    # Calculate weighted median\n",
    "    sorted_indices = np.argsort(flattened_earnings)\n",
    "    sorted_earnings = flattened_earnings[sorted_indices]\n",
    "    sorted_weights = flattened_weights[sorted_indices]\n",
    "    cumsum_weights = np.cumsum(sorted_weights)\n",
    "    cutoff = 0.5 * cumsum_weights[-1]\n",
    "    median_earn = sorted_earnings[np.searchsorted(cumsum_weights, cutoff)]\n",
    "\n",
    "    # Calculate weighted variance\n",
    "    var_earn = np.average((flattened_earnings - mean_earn) ** 2, weights=flattened_weights)\n",
    "\n",
    "    # Calculate weighted standard deviation\n",
    "    std_earn = np.sqrt(var_earn)\n",
    "\n",
    "    # Calculate weighted min and max\n",
    "    min_earn = np.min(flattened_earnings)\n",
    "    max_earn = np.max(flattened_earnings)\n",
    "\n",
    "    # Calculate weighted percentiles\n",
    "    pct_10 = np.percentile(sorted_earnings, 10)\n",
    "    pct_25 = np.percentile(sorted_earnings, 25)\n",
    "    pct_75 = np.percentile(sorted_earnings, 75)\n",
    "    pct_90 = np.percentile(sorted_earnings, 90)\n",
    "\n",
    "    # Step 5: Return the results in a dictionary\n",
    "    ret_dict = {\n",
    "        \"mean\": mean_earn,\n",
    "        \"median\": median_earn,\n",
    "        \"var\": var_earn,\n",
    "        \"std_dev\": std_earn,\n",
    "        \"min\": min_earn,\n",
    "        \"max\": max_earn,\n",
    "        \"P10\": pct_10,\n",
    "        \"P25\": pct_25,\n",
    "        \"P75\": pct_75,\n",
    "        \"P90\": pct_90\n",
    "    }\n",
    "    \n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 19379.731315636927\n",
      "median 18009.228137112274\n",
      "var 35443484.60400763\n",
      "std_dev 5953.443088163994\n",
      "min 10167.349416021754\n",
      "max 43861.918630367705\n",
      "P10 13258.879286215079\n",
      "P25 17764.1456557669\n",
      "P75 35456.598672886765\n",
      "P90 40240.1931268724\n",
      "\n",
      "mean 19397.83155707708\n",
      "median 17135.199644198972\n",
      "var 35391965.63177162\n",
      "std_dev 5949.114693109524\n",
      "min 10281.118964055215\n",
      "max 41124.47926121102\n",
      "P10 13365.454730118185\n",
      "P25 17135.19923562021\n",
      "P75 34270.39737541982\n",
      "P90 38040.14297904782\n",
      "\n",
      "mean 19606.560676050165\n",
      "median 18452.444295196558\n",
      "var 33061170.74817501\n",
      "std_dev 5749.884411722988\n",
      "min 9936.425516120806\n",
      "max 54498.69651873094\n",
      "P10 13535.504917704566\n",
      "P25 20228.41972251277\n",
      "P75 39648.85714550158\n",
      "P90 46289.78922113131\n"
     ]
    }
   ],
   "source": [
    "earnings = lab_earn_trim \n",
    "weights_lab_fe = myPars.lab_fe_weights\n",
    "weights_H_type = myPars.H_type_perm_weights\n",
    "lt_stats = calculate_weighted_lt_stats(earnings, weights_lab_fe, weights_H_type)\n",
    "for key in lt_stats:\n",
    "    print(key, lt_stats[key])\n",
    "\n",
    "print()\n",
    "\n",
    "# earnings_tc = lab_earn_trim_tc\n",
    "# weights_lab_fe = myPars_tc.lab_fe_weights\n",
    "# weights_H_type = myPars_tc.H_type_perm_weights\n",
    "# lt_stats_tc = calculate_weighted_lt_stats(earnings_tc, weights_lab_fe, weights_H_type)\n",
    "# for key in lt_stats_tc:\n",
    "    # print(key, lt_stats_tc[key])\n",
    "\n",
    "# print()\n",
    "\n",
    "earnings_no_wH = lab_earn_trim_no_wH \n",
    "weights_lab_fe = myPars_no_wH.lab_fe_weights\n",
    "weights_H_type = myPars_no_wH.H_type_perm_weights\n",
    "lt_stats_no_wH = calculate_weighted_lt_stats(earnings_no_wH, weights_lab_fe, weights_H_type)\n",
    "for key in lt_stats_no_wH:\n",
    "    print(key, lt_stats_no_wH[key])\n",
    "\n",
    "print()\n",
    "\n",
    "earnings_H_good = lab_earn_trim_H_good\n",
    "weights_lab_fe = myPars_H_good.lab_fe_weights\n",
    "weights_H_type = myPars_H_good.H_type_perm_weights\n",
    "lt_stats_H_good = calculate_weighted_lt_stats(earnings_H_good, weights_lab_fe, weights_H_type)\n",
    "for key in lt_stats_H_good:\n",
    "    print(key, lt_stats_H_good[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_earn: 35443.48\n",
      "var_earn_H: 33061.17\n",
      "liftetime earn var %: 6.721443679844195\n",
      "log lifetime earn var %: 6.957994034791781\n"
     ]
    }
   ],
   "source": [
    "var_earn = lt_stats[\"var\"]\n",
    "var_earn_H = lt_stats_H_good[\"var\"]\n",
    "print(f\"var_earn: {round(var_earn/1000, 2)}\")\n",
    "print(f\"var_earn_H: {round(var_earn_H/1000, 2)}\")\n",
    "print(f\"liftetime earn var %: {(var_earn - var_earn_H)/var_earn*100}\")\n",
    "print(f\"log lifetime earn var %: {(np.log(var_earn) - np.log(var_earn_H))*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0    20274.967\n",
      "Name: mean, dtype: float64\n",
      "std_dev 0    10876.716\n",
      "Name: std_dev, dtype: float64\n",
      "P10 0    8689.2451\n",
      "Name: P10, dtype: float64\n",
      "P25 0    12836.752\n",
      "Name: P25, dtype: float64\n",
      "P50 0    18606.549\n",
      "Name: P50, dtype: float64\n",
      "P75 0    26088.908\n",
      "Name: P75, dtype: float64\n",
      "P90 0    34577.691\n",
      "Name: P90, dtype: float64\n",
      "PDF successfully created at C:/Users/Ben/My Drive/PhD/PhD Year 3/3rd Year Paper/Model/My Code/MH_Model/my_code/model_uncert/output/lt_earnings_stats_tc_counter.pdf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import my_toolbox as tb\n",
    "outpath = myPars.path + \"output/\"\n",
    "\n",
    "lt_stats_data_path = input_path + \"lt_earn_stats.csv\" \n",
    "lt_stats_df =  pd.read_csv(lt_stats_data_path)\n",
    "# change the column names\n",
    "lt_stats_df.columns = [\"mean\", \"std_dev\",  \"P10\", \"P25\", \"P50\", \"P75\", \"P90\"]\n",
    "# convert to dictionary\n",
    "lt_stats_data = lt_stats_df.to_dict(orient = \"records\")[0]\n",
    "for key in lt_stats_df:\n",
    "    print(key, lt_stats_df[key])\n",
    "\n",
    "r2f =lambda x : round(x/1000, 2) \n",
    "r2 = lambda x : round(x, 2)\n",
    "rf = lambda x : round(x/1000)\n",
    "\n",
    "tab = [\n",
    "    \"\\\\documentclass[border=3mm,preview]{standalone}\",\n",
    "    \"\\\\usepackage{booktabs} \\n\",\n",
    "    \"\\\\usepackage{caption} \\n\",\n",
    "    \"\\\\usepackage{pdflscape} \\n\",\n",
    "    \"\\\\begin{document}\\n\",\n",
    "    \"\\\\begin{landscape}\\n\",\n",
    "    # \"\\\\textit{Liftime Earnings Statistics} \\\\\\\\ \\n\",\n",
    "    \"\\\\small\\n\",\n",
    "    \"\\\\begin{table} \\n\",\n",
    "    \"\\\\center\\\\caption*{Annualized Lifetime Earnings Statistics (1000s GBP)} \\n\",\n",
    "    \"\\\\begin{tabular}{l | l l l | l l l l l | l l l} \\n\",\n",
    "    \"\\\\toprule \\n\",\n",
    "    \" & \\\\multicolumn{3}{c}{Summary} & \\\\multicolumn{5}{c}{Percentiles} & \\\\multicolumn{3}{c}{Ratios} \\\\\\\\ \\n\",\n",
    "    # \"\\\\hline \\n\",\n",
    "    \"Source & Mean & Var. & SD & 10th & 25th & 50th & 75th & 90th & 90/10 & 90/50 & 50/10 \\\\\\\\ \\n\", \n",
    "    \"\\\\midrule \\n\",\n",
    "    f\"\"\"Baseline Model & {r2f(lt_stats['mean'])} & {rf(lt_stats['var'])} & {r2f(lt_stats['std_dev'])} & \n",
    "        {r2f(lt_stats['P10'])} & {r2f(lt_stats['P25'])} & {r2f(lt_stats['median'])} & {r2f(lt_stats['P75'])} & {r2f(lt_stats['P90'])} &\n",
    "        {r2(lt_stats['P90']/lt_stats['P10'])} & {r2(lt_stats['P90']/lt_stats['median'])} & {r2(lt_stats['median']/lt_stats['P10'])} \\\\\\\\ \\n\"\"\",\n",
    "    f\"\"\"$H = Good$ & {r2f(lt_stats_H_good['mean'])} & {rf(lt_stats_H_good['var'])} & {r2f(lt_stats_H_good['std_dev'])} & \n",
    "        {r2f(lt_stats_H_good['P10'])} & {r2f(lt_stats_H_good['P25'])} & {r2f(lt_stats_H_good['median'])} & {r2f(lt_stats_H_good['P75'])} & {r2f(lt_stats_H_good['P90'])} &\n",
    "        {r2(lt_stats_H_good['P90']/lt_stats_H_good['P10'])} & {r2(lt_stats_H_good['P90']/lt_stats_H_good['median'])} \n",
    "        & {r2(lt_stats_H_good['median']/lt_stats_H_good['P10'])} \\\\\\\\ \\n\"\"\",\n",
    "    # f\"\"\"$Time Cost$ & {r2f(lt_stats_tc['mean'])} & {rf(lt_stats_tc['var'])} & {r2f(lt_stats_tc['std_dev'])} & \n",
    "    #     {r2f(lt_stats_tc['P10'])} & {r2f(lt_stats_tc['P25'])} & {r2f(lt_stats_tc['median'])} & {r2f(lt_stats_tc['P75'])} & {r2f(lt_stats_tc['P90'])} &\n",
    "    #     {r2(lt_stats_tc['P90']/lt_stats_tc['P10'])} & {r2(lt_stats_tc['P90']/lt_stats_tc['median'])} \n",
    "    #     & {r2(lt_stats_tc['median']/lt_stats_tc['P10'])} \\\\\\\\ \\n\"\"\",\n",
    "    # f\"\"\"Data & {r2f(lt_stats_data['mean'])} & - & {r2f(lt_stats_data['std_dev'])} & \n",
    "    #     {r2f(lt_stats_data['P10'])} & {r2f(lt_stats_data['P25'])} & {r2f(lt_stats_data['P50'])} & {r2f(lt_stats_data['P75'])} & {r2f(lt_stats_data['P90'])} &\n",
    "    #     {r2(lt_stats_data['P90']/lt_stats_data['P10'])} & {r2(lt_stats_data['P90']/lt_stats_data['P50'])} & {r2(lt_stats_data['P50']/lt_stats_data['P10'])} \\\\\\\\ \\n\"\"\",\n",
    "    \"\\\\bottomrule \\n\",   \n",
    "    \"\\\\end{tabular}\\n\",\n",
    "    \"\\\\end{table}\\n\",\n",
    "    \"\\\\end{landscape}\\n\",\n",
    "    \"\\\\end{document}\\n\"\n",
    "]\n",
    "\n",
    "file_name = \"lt_earnings_stats_tc_counter.tex\"\n",
    "tb.list_to_tex(outpath, file_name, tab)\n",
    "tb.tex_to_pdf(outpath, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 9.795433876793231\n",
      "median 9.767647723734388\n",
      "var 0.08901373479963338\n",
      "std_dev 0.29835169649196464\n",
      "min 9.193967966150208\n",
      "max 10.661222119088157\n",
      "P10 9.458403744965052\n",
      "P25 9.751365345094815\n",
      "P75 10.444431549942056\n",
      "P90 10.574529888339155\n",
      "\n",
      "mean 9.798092504087542\n",
      "median 9.718960104682152\n",
      "var 0.08937560930901807\n",
      "std_dev 0.29895753763539407\n",
      "min 9.20813437354156\n",
      "max 10.594428845674196\n",
      "P10 9.46704824875747\n",
      "P25 9.718960075261995\n",
      "P75 10.412107213022406\n",
      "P90 10.516118595324077\n",
      "\n",
      "mean 9.779022959010264\n",
      "median 9.760613208611813\n",
      "var 0.08149608940709699\n",
      "std_dev 0.28547519928550186\n",
      "min 9.155218607433747\n",
      "max 10.88482972179721\n",
      "P10 9.478895863357364\n",
      "P25 9.836326145211341\n",
      "P75 10.528312831827314\n",
      "P90 10.673485664504703\n"
     ]
    }
   ],
   "source": [
    "earnings = log_lab_earn \n",
    "weights_lab_fe = myPars.lab_fe_weights\n",
    "weights_H_type = myPars.H_type_perm_weights\n",
    "lt_stats = calculate_weighted_lt_stats(earnings, weights_lab_fe, weights_H_type)\n",
    "for key in lt_stats:\n",
    "    print(key, lt_stats[key])\n",
    "\n",
    "print()\n",
    "\n",
    "earnings_no_wH = log_lab_earn_no_wH\n",
    "weights_lab_fe = myPars_no_wH.lab_fe_weights\n",
    "weights_H_type = myPars_no_wH.H_type_perm_weights\n",
    "lt_stats_no_wH = calculate_weighted_lt_stats(earnings_no_wH, weights_lab_fe, weights_H_type)\n",
    "for key in lt_stats_no_wH:\n",
    "    print(key, lt_stats_no_wH[key])\n",
    "\n",
    "print()\n",
    "\n",
    "earnings_H_good = log_lab_earn_H_good\n",
    "weights_lab_fe = myPars_H_good.lab_fe_weights\n",
    "weights_H_type = myPars_H_good.H_type_perm_weights\n",
    "lt_stats_H_good = calculate_weighted_lt_stats(earnings_H_good, weights_lab_fe, weights_H_type)\n",
    "for key in lt_stats_H_good:\n",
    "    print(key, lt_stats_H_good[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_earn: 0.08901373479963338\n",
      "var_earn_H: 0.08149608940709699\n",
      "liftetime earn var %: 9.22454739513149\n",
      "log lifetime earn var %: 8.823564505626313\n",
      "raw diff: 0.007517645392536396\n"
     ]
    }
   ],
   "source": [
    "var_earn = lt_stats[\"var\"]\n",
    "var_earn_H = lt_stats_H_good[\"var\"]\n",
    "print(f\"var_earn: {var_earn}\")\n",
    "print(f\"var_earn_H: {var_earn_H}\")\n",
    "print(f\"liftetime earn var %: {((var_earn - var_earn_H)/var_earn_H)*100}\")\n",
    "print(f\"log lifetime earn var %: {(np.log(var_earn) - np.log(var_earn_H))*100}\")\n",
    "print(f'raw diff: {var_earn - var_earn_H}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
